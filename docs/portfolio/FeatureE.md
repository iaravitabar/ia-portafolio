---
title: "Featrure Engineering Simple + Modelo Base 丘뙖잺"
date: 12-08-2025
---

# Feature Engineering Simple + Modelo Base 丘뙖잺

Para esta segunda pr치ctica retomamos la pr치ctica anterior sobre el dataset del Titanic para documentar el proceso de caracteristicas simple y la creacion del modelo de lasificacion base para el dataset. 

## Contexto 游뱂游눬

El objetivo de esta pr치ctica es tomar un conjunto de datos (el del Titanic), y aplicar t칠cnicas b치sicas de Feature Engineering para mejorar la calidad y las predicciones, para entrenar un modelo simple de Regresi칩n Log칤stica. Fundamentalmente, se busca establecer un modelo base (baseline) para tener una referencia clara del rendimiento y asegurar que nuestro modelo es 칰til.

### Actividad 0: Investigaci칩n Te칩rica
Antes de seguir con la implementaci칩n, me gustar칤a dejar registrada la actividad 0 como huella te칩rica. Me sirvi칩 para entender componentes clave que se usar치n. Las preguntas gu칤a fueron:

??? tip "Investigaci칩n de Scikit-learn"
    ###`LogisticRegression`:
    Resuelve problemas de clasificaci칩n.  Estima prob de que una instancia sea de una clase espec칤fica. Mapea la salida en prob entre 1 y 0
    - ** `C` **: par치metro de regularzaci칩n. Inverso a fuerza refularizaci칩n, valores m치s peque침os indican una regularizaci칩n m치s fuerte
    - `penalty`: especifica la norma de regularizaci칩n a usar ('l2'mas comun) mientras que 'l1' puede llevar a la selecci칩n de caracter칤sticas (algunos coeficientes se vuelven cero)
    - `solver`: algoritmo a usar en el problema de optimizaci칩n. La elecci칩n depende del tama침o del dataset y la penalizaci칩n elegida
    - `liblinear` es una buena opci칩n para **datasets peque침os**. Funciona bien con penalizaciones L1 y L2
    - Para **datasets grandes**, solvers como `sag`, `saga`son m치s r치pidos. No todos los solvers soportan todas las penalizaciones (`lbfgs` solo soporta 'l2')

    ###`DummyClassifier`:
    - Sirve para crear un **baseline o pto de referencia**.clasificador muy simple que no aprende de los datos, sino hace predicciones basadas en estrategias triviales
    -`most_frequent`: siempre predice la clase m치s com칰n en el conjunto de entrenamiento
    -`stratified`: hace predicciones aleatorias pero manteniendo la distribuci칩n de clases del conj de entrenamiento
    -`uniform`: predice clases de forma aleatoria con = probabilidad para cada una
    -importancia baseline: **contextualizar el rendimiento** del modelo. Si un modelo complejo no supera significativamente a un baseline simple, significa que el modelo no est치             aprendiendo patrones 칰tiles o que el problema es muy dif칤cil. Nos dice si nuestro esfuerzo est치 valiendo la pena
          
    ###`train_test_split`:
    - `stratify`: hace que la divisi칩n de los datos mantenga la **misma proporci칩n de cada clase** que en el conjunto de datos original. Es fundamental en problemas con clases                            desbalanceadas para que tanto el conjunto de entrenamiento como el de prueba sean representativos
    - Por qu칠 usar `random_state`? 
        para garantizar la **reproducibilidad**. Al fijar un `random_state` (cualquier num entero), la div de los datos ser치 siempre la misma cada vez que se     ejecute el                     c칩digo.clave para depurar y comparar el rendimiento de diferentes modelos de manera justa
    - 쯈u칠 porcentaje de test es recomendable?
         No hay regla 칰nica, pero las divisiones comunes son **80/20** o **70/30** (entrenamiento/prueba). Para datasets muy grandes, el porcentaje de prueba puede ser menor. Un                 20% es un buen punto de partida 
        
    ###`m칠tricas de evaluaci칩n`:
    - **쯈u칠 significa cada m칠trica en `classification_report`?**
      - `precision`: De todas las veces que el modelo predijo una clase, 쯈UE porcentaje fue correcto? (Mide calidad de las predicciones positivas)
      - `recall` (sensibilidad): De todos los ejemplos reales de una clase, 쯤u칠 porcentaje detect칩 el modelo? (Mide capacidad del modelo para encontrar todos los pos)
      - `f1-score`: Es la media de `precision` y `recall`. Es una m칠trica 칰nica que balancea las dos, 칰til cuando nos importan tanto los falsos positivos como los falsos negativos
      - `support`: n칰mero de muestras reales de cada clase en los datos

    - **쮺칩mo interpretar la matriz de confusi칩n?**
        -Es una tabla que resume los aciertos y errores. Para una clasificaci칩n binaria:
      - **Diagonal principal (arriba-izq a abajo-der)**: Los aciertos (Verdaderos Nega, Verdaderos Posi)
      - **Fuera de la diagonal**: Los errores (Falsos Posi, Falsos Nega)

    - **쮺u치ndo usar `accuracy` vs otras m칠tricas?**
        - `accuracy` (precisi칩n global) cuando las **clases est치n balanceadas**
        - `precision`, `recall` y `f1-score` cuando las **clases est치n desbalanceadas**. `accuracy` puede ser tricky, xq un modelo puede tener una alta precisi칩n solo                              prediciendo siempre la clase mayoritaria


## Objetivos 

## Actividades

## Desarrollo

## Evidencias
- resulta2

## Reflexiones

## Ref
