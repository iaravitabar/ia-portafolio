---
title: "Featrure Engineering Simple + Modelo Base ⚙️"
date: 12-08-2025
---

# Feature Engineering Simple + Modelo Base ⚙️

Para esta segunda práctica retomamos la práctica anterior sobre el dataset del Titanic para documentar el proceso de caracteristicas simple y la creacion del modelo de lasificacion base para el dataset. 

## Contexto 🤔💭

El objetivo de esta práctica es tomar un conjunto de datos (el del Titanic), y aplicar técnicas básicas de Feature Engineering para mejorar la calidad y las predicciones, para entrenar un modelo simple de Regresión Logística. Fundamentalmente, se busca establecer un modelo base (baseline) para tener una referencia clara del rendimiento y asegurar que nuestro modelo es útil.

### Actividad 0: Investigación Teórica
Antes de seguir con la implementación, me gustaría dejar registrada la actividad 0 como huella teórica. Me sirvió para entender componentes clave que se usarán. Las preguntas guía fueron:

!!! tip "Investigación de Scikit-learn"
    - **`LogisticRegression`**:
        - ¿Qué tipo de problema resuelve?
        - ¿Qué parámetros importantes tiene?
        - ¿Cuándo usar `solver='liblinear'` vs otros solvers?
    - **`DummyClassifier`**:
        - ¿Para qué sirve exactamente?
        - ¿Qué estrategias de baseline ofrece?
        - ¿Por qué es importante tener un baseline?
    - **`train_test_split`**:
        - ¿Qué hace el parámetro `stratify`?
        - ¿Por qué usar `random_state`?
        - ¿Qué porcentaje de test es recomendable?
    - **Métricas de evaluación**:
        - ¿Qué significa cada métrica en `classification_report`?
        - ¿Cómo interpretar la matriz de confusión?
        - ¿Cuándo usar `accuracy` vs otras métricas?

## Objetivos 

## Actividades

## Desarrollo

## Evidencias
- resulta2

## Reflexiones

## Ref
