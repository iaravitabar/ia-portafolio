---
title: "Featrure Engineering Simple + Modelo Base âš™ï¸"
date: 12-08-2025
---

# Feature Engineering Simple + Modelo Base âš™ï¸

Para esta segunda prÃ¡ctica retomamos la prÃ¡ctica anterior sobre el dataset del Titanic para documentar el proceso de caracteristicas simple y la creacion del modelo de lasificacion base para el dataset. 

## Contexto ğŸ¤”ğŸ’­

El objetivo de esta prÃ¡ctica es tomar un conjunto de datos (el del Titanic), y aplicar tÃ©cnicas bÃ¡sicas de Feature Engineering para mejorar la calidad y las predicciones, para entrenar un modelo simple de RegresiÃ³n LogÃ­stica. Fundamentalmente, se busca establecer un modelo base (baseline) para tener una referencia clara del rendimiento y asegurar que nuestro modelo es Ãºtil.

### Actividad 0: InvestigaciÃ³n TeÃ³rica
Antes de seguir con la implementaciÃ³n, me gustarÃ­a dejar registrada la actividad 0 como huella teÃ³rica. Me sirviÃ³ para entender componentes clave que se usarÃ¡n. Las preguntas guÃ­a fueron:

!!! tip "InvestigaciÃ³n de Scikit-learn"
    - **`LogisticRegression`**:
        - Â¿QuÃ© tipo de problema resuelve?
        - Â¿QuÃ© parÃ¡metros importantes tiene?
        - Â¿CuÃ¡ndo usar `solver='liblinear'` vs otros solvers?
    - **`DummyClassifier`**:
        - Â¿Para quÃ© sirve exactamente?
        - Â¿QuÃ© estrategias de baseline ofrece?
        - Â¿Por quÃ© es importante tener un baseline?
    - **`train_test_split`**:
        - Â¿QuÃ© hace el parÃ¡metro `stratify`?
        - Â¿Por quÃ© usar `random_state`?
        - Â¿QuÃ© porcentaje de test es recomendable?
    - **MÃ©tricas de evaluaciÃ³n**:
        - Â¿QuÃ© significa cada mÃ©trica en `classification_report`?
        - Â¿CÃ³mo interpretar la matriz de confusiÃ³n?
        - Â¿CuÃ¡ndo usar `accuracy` vs otras mÃ©tricas?

## Objetivos 

## Actividades

## Desarrollo

## Evidencias
- resulta2

## Reflexiones

## Ref
